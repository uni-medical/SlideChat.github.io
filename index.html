<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>GMAI-MMBench</title>
  <link rel="icon" type="image/x-icon" href="static/images/mmbench_icon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/OpenGVLab/SAM-Med2D/">
              SAM-Med2D
            </a>
            <a class="navbar-item" href="https://github.com/uni-medical/SAM-Med3D/">
              SAM-Med3D 
              <a class="navbar-item" href="https://github.com/OpenGVLab/Multi-Modality-Arena/">
                OmniMedVQA
              </a>
            </a>
            
            </a>
          </div>
        </div>
      </div>
  
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/> 
              <span class="mmmu" style="vertical-align: middle">GMAI-MMBench</span>
              </h1>
            <h2 class="subtitle is-3 publication-subtitle">
              A Comprehensive Multimodal
              Evaluation Benchmark Towards General Medical AI
              <!-- <br> -->
            </h2>
            </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">Pengcheng Chen*<sup style="color:#ffac33;">1,2</sup>,</span>
                <span class="author-block">Jin Ye*<sup style="color:#ed4b82;">â€ ,1,3</sup>,</span>
                <span class="author-block">Guoan Wang*<sup style="color:#007bff;">1,4</sup>,</span>
                <span class="author-block">Yanjun Li<sup style="color:#007bff;">1,4</sup>,</span><br>
                <span class="author-block">Zhongying Deng<sup style="color:#ffac33;">5</sup>,</span>
                <span class="author-block">Wei Li<sup style="color:#ed4b82;">1,6</sup>,</span>
                <span class="author-block">Tianbin Li<sup style="color:#ed4b82;">1</sup>,</span>
                <span class="author-block">Haodong Duan<sup style="color:#ffac33;">1</sup>,</span>
                <span class="author-block">Ziyan Huang<sup style="color:#ffac33;">1,6</sup>,</span>
                <span class="author-block">Yanzhou Su<sup style="color:#6fbf73;">1</sup>,</span>
                <span class="author-block">Benyou Wang<sup style="color:#9b51e0;">7,8</sup>,</span>
                <span class="author-block">Shaoting Zhang<sup style="color:#6fbf73;">1</sup>,</span>
                <span class="author-block">Bin Fu<sup style="color:#60121572;">9</sup>,</span>
                <span class="author-block">Jianfei Cai<sup style="color:#ed4b82;">3</sup>,</span>
                <span class="author-block">Bohan Zhuang<sup style="color:#ed4b82;">3</sup>,</span>
                <span class="author-block">Eric J Seibel<sup style="color:#ffac33;">2</sup>,</span>
                <span class="author-block">Junjun He<sup style="color:#6fbf73;">â€ ,1</sup>,</span>
                <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">â€ ,1</sup>,</span>
              </div>
          
              <br>
          
              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup style="color:#6fbf73;">1</sup>Shanghai AI Laboratory,</span>
                <span class="author-block"><sup style="color:#ffac33;">2</sup>University of Washington,</span>
                <span class="author-block"><sup style="color:#ed4b82;">3</sup>Monash University,</span>
                <span class="author-block"><sup style="color:#007bff;">4</sup>East China Normal University,</span></br>
                <span class="author-block"><sup style="color:#ffac33;">5</sup>University of Cambridge,</span>
                <span class="author-block"><sup style="color:#ed4b82;">6</sup>Shanghai Jiao Tong University,</span>
                <span class="author-block"><sup style="color:#9b51e0;">7</sup>The Chinese University of Hong Kong, Shenzhen</span>
                <span class="author-block"><sup style="color:#ff00f2;">8</sup>Shenzhen Research Institute of Big Data</span>
                <span class="author-block"><sup style="color:#60121572;">9</sup>Shenzhen Institute of Advanced Technology (SIAT), Chinese Academy of Sciences</span>
              </div>
    
              <br>
              <div class="is-size-5 publication-authors">
                <span class="author-block">*Core Contributors</span><br>
                <span class="author-block">â€ Corresponding to:</span>
                <span class="author-block"><a href="mailto:jin.ye@monash.edu">jin.ye@monash.edu</a>,</span>
                <span class="author-block"><a href="mailto:hejunjun@pjlab.org.cn">hejunjun@pjlab.org.cn</a>,</span>
                <span class="author-block"><a href="mailto:qiaoyu@pjlab.org.cn">qiaoyu@pjlab.org.cn</a>,</span>
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
        <div class="content has-text-centered">
          <img src="static/images/cover.jpg" alt="geometric reasoning" width="100%"/>
          <p>  
            Overview of the GMAI-MMBench. The benchmark is meticulously designed for testing LVLMsâ€™ abilities in real-world clinical scenarios with three key features: (1) Comprehensive medical knowledge: It consists of 285 diverse clinical-related datasets from worldwide sources, covering 38 modalities. (2) Well-categorized data structure: It features 19 clinical VQA tasks and 18 clinical departments, meticulously organized into a lexical tree. (3) Multi-perceptual granularity: Interactive methods span from image to region level, offering varying degrees of perceptual details.
          </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ðŸ””News</h2>
        <div class="content has-text-justified">
          <p>
            <b>ðŸš€[2024-06-05]: Submit on nips2024!ðŸŒŸ</b>
          </p>
      </div>      
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Vision-Language Models (LVLMs) are capable of handling diverse data types such as imaging, text, and physiological signals, and can be applied in various fields. In the medical field, LVLMs have a high potential to offer substantial assistance for diagnosis and treatment. Before that, it is crucial to develop benchmarks to evaluate LVLMsâ€™ effectiveness in various medical applications. Current benchmarks are often built upon specific academic literature, mainly focusing on a single domain, and lacking varying perceptual granularities. Thus, they face specific challenges, including limited clinical relevance, incomplete evaluations, and insufficient guidance for interactive LVLMs. To address these limitations,we developed the GMAI-MMBench, the most comprehensive general medical AI benchmark with well-categorized data structure and multi-perceptual granularity to date. It is constructed from 285 datasets across 38 medical image modalities, 19 clinical-related tasks, 18 departments, and 4 perceptual granularities in a Visual Question Answering (VQA) format. Additionally, we implemented a lexical tree structure that allows users to customize evaluation tasks, accommodating various assessment needs and substantially supporting medical AI research and applications. We evaluated 50 LVLMs, and the results show that even the advanced GPT-4o only achieves an accuracy of 52%, indicating significant room for improvement. Moreover, we identified five key insufficiencies in current cutting-edge LVLMs that need to be addressed to advance the development of better medical applications. We believe GMAI-MMBench will stimulate the community to build the next generation of LVLMs toward GMAI.
            </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mmmu">
    <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/>
    <span class="mmmu" style="vertical-align: middle">GMAI-MMBench</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We propose GMAI-MMBench, an innovative benchmark meticulously designed for the medical field, capable of providing comprehensive evaluations of LVLMs across various aspects of healthcare. We collect 285 datasets from public sources and hospitals, covering medical imaging tasks of detection, classification, and segmentation, to form the data fuel for establishing such a benchmark. The detailed datasets are listed in the supplementary. Based on the data foundation, we design a reliable pipeline to generate question-answering pairs and organize them from different perspectives with manual validation. Finally, we carefully select approximately 26K questions with varying levels of perceptual granularity from the filtered cases to construct the final GMAI-MMBench.
          </p>
           <img src="static/images/Figure2.jpg" alt="algebraic reasoning" class="center">
          </p>
        </div>
    </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Statistics</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/Statistics1.jpg" alt="algebraic reasoning" width="95%"/>
              <p> The three pie charts illustrate the distribution of different clinical VQA tasks, departments, and perceptual granularities. The left pie chart (A) shows the distribution of clinical VQA tasks, with Disease Diagnosis (DD) being the most prevalent at 18.6%, followed by Surgical Instrument Recognition (SIR) at 9.5%, Surgical Workflow Recognition (SWR) at 8.6%, and Anatomical Structure Recognition (ASR) at 8.4%. The middle pie chart (B) depicts the distribution of cases across various departments, where Pulmonary Medicine (PM) has the highest proportion at 16.0%, followed by Hematology (H) at 10.3%, General Surgery (GS) at 10.0%, and Laboratory Medicine and Pathology (LMP) at 11.1%. The right pie chart (C) represents the distribution of perceptual granularities, with Image Level accounting for the largest share at 57.2%, followed by Mask Level at 17.1%, and Contour Level at 11.6%. </p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/Statistics2.jpg" alt="arithmetic reasoning" width="40%"/>
              <p> Statistics of the clinical VQA tasks and its sub-task abbreviations mentioned in the paper with their corresponding full names.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/Statistics3.jpg" alt="arithmetic reasoning" width="80%"/>
              <p> Statistics of the departments and its sub-task abbreviations mentioned in the paper with their corresponding full names.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/Statistics4.jpg" alt="arithmetic reasoning" width="80%"/>
              <p> Statistics of the perceptual granularities. âˆ— and # denote the case for single choice and multiple choice, respectively.</p>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Lexical Tree</h2>
        <div class="content has-text-justified">
          <iframe src="LexicalTree.html" width="100%" height="600px" style="border:none;"></iframe>
          <p>
            In this work, to make the GMAI-MMBench more intuitive and user-friendly, we have systematized our labels and structured the entire dataset into a lexical tree. Users can freely select the test contents based on this lexical tree. We believe that this customizable benchmark will effectively guide the improvement of models in specific areas.
        </p>
        <div class="content has-text-centered">
          <img src="static/images/Lexical Tree_2.jpg" alt="algebraic reasoning" class="center">
          <p> An example of how to use the Lexical Tree for customizing evaluations. The process involves selecting the department (ophthalmology), choosing the modality (fundus photography), filtering questions using relevant keywords, and evaluating different models based on their accuracy in answering the filtered questions. </p>
        </div>
        </div>
    </div>
    </div>
  </div>
</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <!-- <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/> -->
    <h1 class="title is-1 mmmu">Experiment Results</h1>
  </div>
</section>
<section class="section">
  <div class="container">

<!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <button id="toggleButton" onclick="changeButtonText()"><b style='font-size: larger;'>Clinical VQA Tasks Results</b> (Click to Switch)</button>
          <!-- <div class="model-labels-container">
            <span class="leaderboard-label" style="background-color: rgba(255, 208, 80, 0.15);">Human Expert</span>
            <span class="leaderboard-label" style="background-color: rgba(249, 242, 248, 1);">Open-Source</span>
            <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.1);">Proprietary</span>
          </div> -->
          <!-- Validation Set Leaderboard -->
          <table id="table1" class="js-sort-table">
            <caption>Results for single-choice questions of 50 different LVLMs on clinical VQA tasks. The best-performing model in each category is <strong>in-bold</strong>, and the second best is <u>underlined</u>.</caption>
            <thead>
              <tr>
                <th class="js-sort-string"><strong>Model name</strong></th>
                <th class="js-sort-number"><strong>Overall (val)</strong></th>
                <th class="js-sort-number"><strong>Overall (test)</strong></th>
                <th class="js-sort-number"><strong>AR</strong></th>
                <th class="js-sort-number"><strong>BVR</strong></th>
                <th class="js-sort-number"><strong>B</strong></th>
                <th class="js-sort-number"><strong>CR</strong></th>
                <th class="js-sort-number"><strong>C</strong></th>
                <th class="js-sort-number"><strong>DD</strong></th>
                <th class="js-sort-number"><strong>IQG</strong></th>
                <th class="js-sort-number"><strong>MR</strong></th>
                <th class="js-sort-number"><strong>M</strong></th>
                <th class="js-sort-number"><strong>NT</strong></th>
                <th class="js-sort-number"><strong>OR-A</strong></th>
                <th class="js-sort-number"><strong>OR-HN</strong></th>
                <th class="js-sort-number"><strong>OR-P</strong></th>
                <th class="js-sort-number"><strong>OR-T</strong></th>
                <th class="js-sort-number"><strong>SG</strong></th>
                <th class="js-sort-number"><strong>SAR</strong></th>
                <th class="js-sort-number"><strong>SIR</strong></th>
                <th class="js-sort-number"><strong>SWR</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Random</td>
                <td>25.70</td>
                <td>25.94</td>
                <td>38.20</td>
                <td>22.73</td>
                <td>22.92</td>
                <td>22.72</td>
                <td>24.06</td>
                <td>26.66</td>
                <td>27.13</td>
                <td>27.00</td>
                <td>20.00</td>
                <td>24.75</td>
                <td>21.37</td>
                <td>22.93</td>
                <td>22.33</td>
                <td>21.18</td>
                <td>32.43</td>
                <td>24.23</td>
                <td>21.39</td>
                <td>23.71</td>
              </tr>
              <tr>
                <td colspan="21" style="text-align: center; background-color: #EFEFEF;">Medical Special Model</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>MedVInT</td>
                <td>2.29</td>
                <td>1.96</td>
                <td>5.75</td>
                <td>0.00</td>
                <td>0.00</td>
                <td>0.00</td>
                <td>2.56</td>
                <td>2.11</td>
                <td>4.05</td>
                <td>0.00</td>
                <td>0.00</td>
                <td>0.00</td>
                <td>0.11</td>
                <td>0.00</td>
                <td>0.00</td>
                <td>0.12</td>
                <td>7.36</td>
                <td>0.00</td>
                <td>1.88</td>
                <td>0.00</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>Med-Flamingo</td>
                <td>12.74</td>
                <td>11.64</td>
                <td>6.67</td>
                <td>10.14</td>
                <td>9.23</td>
                <td>11.27</td>
                <td>6.62</td>
                <td>13.43</td>
                <td>12.15</td>
                <td>6.38</td>
                <td>8.00</td>
                <td>18.18</td>
                <td>9.26</td>
                <td>18.27</td>
                <td>11.00</td>
                <td>11.53</td>
                <td>12.16</td>
                <td>5.19</td>
                <td>8.47</td>
                <td>11.43</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>LLaVA-Med</td>
                <td>20.54</td>
                <td>19.60</td>
                <td>24.51</td>
                <td>17.83</td>
                <td>17.08</td>
                <td>19.86</td>
                <td>15.04</td>
                <td>19.81</td>
                <td>20.24</td>
                <td>21.51</td>
                <td>13.20</td>
                <td>15.15</td>
                <td>20.42</td>
                <td>23.73</td>
                <td>17.67</td>
                <td>19.65</td>
                <td>21.70</td>
                <td>19.81</td>
                <td>14.11</td>
                <td>20.86</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>Qilin-Med-VL-Chat</td>
                <td>22.34</td>
                <td>22.06</td>
                <td>29.57</td>
                <td>19.41</td>
                <td>16.46</td>
                <td>23.79</td>
                <td>15.79</td>
                <td>24.19</td>
                <td>21.86</td>
                <td>16.62</td>
                <td>7.20</td>
                <td>13.64</td>
                <td>24.00</td>
                <td>14.67</td>
                <td>12.67</td>
                <td>15.53</td>
                <td>26.13</td>
                <td>24.42</td>
                <td>17.37</td>
                <td>25.71</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>RadFM</td>
                <td>22.95</td>
                <td>22.93</td>
                <td>27.16</td>
                <td>20.63</td>
                <td>13.23</td>
                <td>19.14</td>
                <td>20.45</td>
                <td>24.51</td>
                <td>23.48</td>
                <td>22.85</td>
                <td>15.60</td>
                <td>16.16</td>
                <td>14.32</td>
                <td>24.93</td>
                <td>17.33</td>
                <td>21.53</td>
                <td>29.73</td>
                <td>17.12</td>
                <td>19.59</td>
                <td>31.14</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>MedDr</td>
                <td>41.95</td>
                <td>43.69</td>
                <td>41.20</td>
                <td>50.70</td>
                <td>37.85</td>
                <td>29.87</td>
                <td>28.27</td>
                <td>52.53</td>
                <td>36.03</td>
                <td>31.45</td>
                <td>29.60</td>
                <td>47.47</td>
                <td>33.37</td>
                <td>51.33</td>
                <td>32.67</td>
                <td>44.47</td>
                <td>35.14</td>
                <td>25.19</td>
                <td>25.58</td>
                <td>32.29</td>
              </tr>
              <tr>
                <td colspan="21" style="text-align: center; background-color: #FFF3E4;">Open-Source LVLMs</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>CogVLM-grounding-generalist</td>
                <td>5.20</td>
                <td>5.66</td>
                <td>3.11</td>
                <td>4.02</td>
                <td>2.92</td>
                <td>3.22</td>
                <td>10.83</td>
                <td>7.98</td>
                <td>9.72</td>
                <td>0.15</td>
                <td>0.00</td>
                <td>11.11</td>
                <td>8.32</td>
                <td>1.87</td>
                <td>1.67</td>
                <td>2.00</td>
                <td>1.65</td>
                <td>0.00</td>
                <td>4.02</td>
                <td>0.57</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>XComposer</td>
                <td>8.92</td>
                <td>7.67</td>
                <td>1.38</td>
                <td>7.69</td>
                <td>8.31</td>
                <td>12.34</td>
                <td>22.86</td>
                <td>7.31</td>
                <td>6.07</td>
                <td>5.49</td>
                <td>2.80</td>
                <td>16.16</td>
                <td>5.05</td>
                <td>8.67</td>
                <td>2.00</td>
                <td>9.76</td>
                <td>11.94</td>
                <td>7.31</td>
                <td>3.17</td>
                <td>4.00</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>PandaGPT 13B</td>
                <td>16.69</td>
                <td>16.27</td>
                <td>24.51</td>
                <td>23.60</td>
                <td>22.15</td>
                <td>23.61</td>
                <td>14.29</td>
                <td>14.95</td>
                <td>13.36</td>
                <td>12.17</td>
                <td>18.40</td>
                <td>28.79</td>
                <td>18.63</td>
                <td>27.33</td>
                <td>18.67</td>
                <td>16.71</td>
                <td>11.04</td>
                <td>9.23</td>
                <td>13.43</td>
                <td>9.71</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Flamingo v2</td>
                <td>25.58</td>
                <td>26.34</td>
                <td>37.74</td>
                <td>21.50</td>
                <td>20.62</td>
                <td>22.00</td>
                <td>22.41</td>
                <td>27.29</td>
                <td>25.91</td>
                <td>27.45</td>
                <td>18.00</td>
                <td>28.79</td>
                <td>25.16</td>
                <td>22.13</td>
                <td>22.00</td>
                <td>22.00</td>
                <td>34.61</td>
                <td>22.88</td>
                <td>20.44</td>
                <td>27.43</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>VisualGLM-6B</td>
                <td>29.58</td>
                <td>30.45</td>
                <td>40.16</td>
                <td>33.92</td>
                <td>24.92</td>
                <td>25.22</td>
                <td>24.21</td>
                <td>32.99</td>
                <td>29.96</td>
                <td>29.53</td>
                <td>21.20</td>
                <td>37.88</td>
                <td>30.32</td>
                <td>24.80</td>
                <td>13.33</td>
                <td>29.88</td>
                <td>33.11</td>
                <td>19.62</td>
                <td>19.16</td>
                <td>37.43</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Idefics-9B-Instruct</td>
                <td>29.74</td>
                <td>31.13</td>
                <td>40.39</td>
                <td>30.59</td>
                <td>26.46</td>
                <td>33.63</td>
                <td>22.56</td>
                <td>34.38</td>
                <td>25.51</td>
                <td>26.71</td>
                <td>21.60</td>
                <td>27.78</td>
                <td>27.47</td>
                <td>32.80</td>
                <td>24.67</td>
                <td>23.41</td>
                <td>32.66</td>
                <td>23.08</td>
                <td>21.39</td>
                <td>30.57</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InstructBLIP-7B</td>
                <td>31.80</td>
                <td>30.95</td>
                <td>42.12</td>
                <td>26.92</td>
                <td>24.92</td>
                <td>28.09</td>
                <td>21.65</td>
                <td>34.58</td>
                <td>31.58</td>
                <td>29.23</td>
                <td>22.40</td>
                <td>30.30</td>
                <td>28.95</td>
                <td>27.47</td>
                <td>23.00</td>
                <td>24.82</td>
                <td>32.88</td>
                <td>19.81</td>
                <td>21.64</td>
                <td>26.57</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Mini-Gemini-7B</td>
                <td>32.17</td>
                <td>31.09</td>
                <td>29.69</td>
                <td>39.16</td>
                <td>31.85</td>
                <td>28.26</td>
                <td>10.38</td>
                <td>35.58</td>
                <td>29.96</td>
                <td>28.78</td>
                <td>20.80</td>
                <td>34.34</td>
                <td>29.58</td>
                <td>36.53</td>
                <td>24.00</td>
                <td>31.76</td>
                <td>22.45</td>
                <td>25.96</td>
      <td>18.56</td>
      <td>29.43</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MMAlaya</td>
      <td>32.19</td>
      <td>32.30</td>
      <td>41.20</td>
      <td>35.14</td>
      <td>32.15</td>
      <td>34.17</td>
      <td>27.82</td>
      <td>35.09</td>
      <td>28.34</td>
      <td>30.27</td>
      <td>18.00</td>
      <td>46.97</td>
      <td>20.21</td>
      <td>31.20</td>
      <td>16.00</td>
      <td>34.59</td>
      <td>32.28</td>
      <td>23.65</td>
      <td>22.93</td>
      <td>30.29</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Qwen-VL</td>
      <td>34.80</td>
      <td>36.05</td>
      <td>37.05</td>
      <td>37.24</td>
      <td>35.85</td>
      <td>28.98</td>
      <td>24.81</td>
      <td>43.60</td>
      <td>24.70</td>
      <td>30.12</td>
      <td>19.20</td>
      <td>44.44</td>
      <td>29.68</td>
      <td>31.87</td>
      <td>25.00</td>
      <td>31.18</td>
      <td>30.26</td>
      <td>21.54</td>
      <td>20.10</td>
      <td>26.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Yi-VL-6B</td>
      <td>34.82</td>
      <td>34.31</td>
      <td>41.66</td>
      <td>39.16</td>
      <td>26.62</td>
      <td>30.23</td>
      <td>31.88</td>
      <td>38.01</td>
      <td>26.72</td>
      <td>24.93</td>
      <td>25.20</td>
      <td>37.37</td>
      <td>29.58</td>
      <td>31.20</td>
      <td>32.33</td>
      <td>30.59</td>
      <td>36.71</td>
      <td>24.81</td>
      <td>23.18</td>
      <td>31.43</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLaVA-NeXT-vicuna-7B</td>
      <td>34.86</td>
      <td>35.42</td>
      <td>40.62</td>
      <td>38.64</td>
      <td>21.08</td>
      <td>35.42</td>
      <td>23.91</td>
      <td>41.22</td>
      <td>32.39</td>
      <td>28.04</td>
      <td>20.53</td>
      <td>44.95</td>
      <td>27.92</td>
      <td>34.98</td>
      <td>20.22</td>
      <td>32.82</td>
      <td>33.63</td>
      <td>23.08</td>
      <td>25.06</td>
      <td>34.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Qwen-VL-Chat</td>
      <td>35.07</td>
      <td>36.96</td>
      <td>38.09</td>
      <td>40.56</td>
      <td>38.00</td>
      <td>32.20</td>
      <td>25.71</td>
      <td>44.07</td>
      <td>24.70</td>
      <td>30.56</td>
      <td>24.00</td>
      <td>40.91</td>
      <td>29.37</td>
      <td>36.53</td>
      <td>26.00</td>
      <td>27.29</td>
      <td>35.14</td>
      <td>16.54</td>
      <td>20.10</td>
      <td>34.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>CogVLM-Chat</td>
      <td>35.23</td>
      <td>36.08</td>
      <td>40.97</td>
      <td>30.77</td>
      <td>27.69</td>
      <td>32.74</td>
      <td>19.40</td>
      <td>41.10</td>
      <td>36.84</td>
      <td>34.72</td>
      <td>24.00</td>
      <td>40.91</td>
      <td>36.74</td>
      <td>37.33</td>
      <td>26.00</td>
      <td>33.65</td>
      <td>36.56</td>
      <td>20.19</td>
      <td>23.95</td>
      <td>26.57</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Monkey</td>
      <td>35.48</td>
      <td>36.39</td>
      <td>38.32</td>
      <td>35.31</td>
      <td>35.54</td>
      <td>34.53</td>
      <td>23.16</td>
      <td>43.40</td>
      <td>31.98</td>
      <td>30.12</td>
      <td>19.20</td>
      <td>33.33</td>
      <td>30.00</td>
      <td>32.53</td>
      <td>25.33</td>
      <td>31.65</td>
      <td>34.46</td>
      <td>20.00</td>
      <td>20.27</td>
      <td>30.29</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>mPLUG-Owl2</td>
      <td>35.62</td>
      <td>36.21</td>
      <td>37.51</td>
      <td>41.08</td>
      <td>30.92</td>
      <td>38.10</td>
      <td>27.82</td>
      <td>41.59</td>
      <td>28.34</td>
      <td>32.79</td>
      <td>22.40</td>
      <td>40.91</td>
      <td>24.74</td>
      <td>38.27</td>
      <td>23.33</td>
      <td>36.59</td>
      <td>33.48</td>
      <td>20.58</td>
      <td>23.01</td>
      <td>32.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>ShareCaptioner</td>
      <td>36.37</td>
      <td>36.19</td>
      <td>42.35</td>
      <td>32.69</td>
      <td>31.08</td>
      <td>27.19</td>
      <td>30.83</td>
      <td>41.19</td>
      <td>30.36</td>
      <td>33.23</td>
      <td>28.40</td>
      <td>42.93</td>
      <td>27.79</td>
      <td>33.73</td>
      <td>28.33</td>
      <td>40.71</td>
      <td>29.58</td>
      <td>20.96</td>
      <td>28.83</td>
      <td>30.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Emu2-Chat</td>
      <td>36.50</td>
      <td>37.59</td>
      <td>43.27</td>
      <td>47.73</td>
      <td>26.31</td>
      <td>40.07</td>
      <td>28.12</td>
      <td>44.00</td>
      <td>36.44</td>
      <td>28.49</td>
      <td>20.40</td>
      <td>31.82</td>
      <td>26.74</td>
      <td>37.60</td>
      <td>26.67</td>
      <td>29.76</td>
      <td>33.63</td>
      <td>23.27</td>
      <td>26.43</td>
      <td>29.43</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>XComposer2-4KHD</td>
      <td>36.66</td>
      <td>38.54</td>
      <td>41.89</td>
      <td>39.86</td>
      <td>28.77</td>
      <td>40.43</td>
      <td>20.60</td>
      <td>44.25</td>
      <td>35.22</td>
      <td>33.53</td>
      <td>22.80</td>
      <td>42.42</td>
      <td>34.84</td>
      <td>29.60</td>
      <td>44.00</td>
      <td>39.53</td>
      <td>35.21</td>
      <td>21.54</td>
      <td>27.20</td>
      <td>38.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>ShareGPT4V-7B</td>
      <td>36.71</td>
      <td>36.70</td>
      <td>43.96</td>
      <td>37.59</td>
      <td>21.54</td>
      <td>37.57</td>
      <td>18.80</td>
      <td>43.26</td>
      <td>32.39</td>
      <td>27.30</td>
      <td>22.80</td>
      <td>43.43</td>
      <td>29.47</td>
      <td>37.33</td>
      <td>22.00</td>
      <td>31.76</td>
      <td>34.98</td>
      <td>24.42</td>
      <td>25.06</td>
      <td>30.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLaVA-NeXT-mistral-7B</td>
      <td>37.20</td>
      <td>37.16</td>
      <td>38.43</td>
      <td>27.98</td>
      <td>20.31</td>
      <td>29.16</td>
      <td>20.60</td>
      <td>47.19</td>
      <td>30.36</td>
      <td>32.64</td>
      <td>22.40</td>
      <td>55.56</td>
      <td>32.75</td>
      <td>25.58</td>
      <td>17.56</td>
      <td>34.04</td>
      <td>28.38</td>
      <td>23.27</td>
      <td>24.12</td>
      <td>37.43</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-13b-xtuner</td>
      <td>37.82</td>
      <td>38.74</td>
      <td>44.65</td>
      <td>29.02</td>
      <td>27.08</td>
      <td>38.28</td>
      <td>28.87</td>
      <td>45.32</td>
      <td>32.79</td>
      <td>30.12</td>
      <td>20.40</td>
      <td>45.96</td>
      <td>33.47</td>
      <td>42.53</td>
      <td>44.33</td>
      <td>37.53</td>
      <td>33.48</td>
      <td>19.62</td>
      <td>22.58</td>
      <td>35.43</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>OmniLMM-12B</td>
      <td>37.89</td>
      <td>39.30</td>
      <td>39.82</td>
      <td>40.56</td>
      <td>32.62</td>
      <td>37.57</td>
      <td>24.81</td>
      <td>46.68</td>
      <td>35.63</td>
      <td>35.01</td>
      <td>27.60</td>
      <td>57.58</td>
      <td>28.42</td>
      <td>34.00</td>
      <td>25.00</td>
      <td>29.18</td>
      <td>34.46</td>
      <td>24.42</td>
      <td>27.54</td>
      <td>40.29</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.1</td>
      <td>38.16</td>
      <td>39.41</td>
      <td>42.46</td>
      <td>43.88</td>
      <td>35.23</td>
      <td>45.08</td>
      <td>23.31</td>
      <td>45.96</td>
      <td>38.87</td>
      <td>29.23</td>
      <td>29.60</td>
      <td>40.40</td>
      <td>31.68</td>
      <td>41.87</td>
      <td>26.67</td>
      <td>38.82</td>
      <td>32.13</td>
      <td>19.42</td>
      <td>25.58</td>
      <td>30.29</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-7B</td>
      <td>38.23</td>
      <td>37.96</td>
      <td>45.45</td>
      <td>34.27</td>
      <td>30.92</td>
      <td>41.32</td>
      <td>21.65</td>
      <td>44.68</td>
      <td>34.01</td>
      <td>27.74</td>
      <td>23.60</td>
      <td>43.43</td>
      <td>28.00</td>
      <td>42.13</td>
      <td>29.00</td>
      <td>35.06</td>
      <td>33.41</td>
      <td>22.12</td>
      <td>23.61</td>
      <td>29.14</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Monkey-Chat</td>
      <td>38.39</td>
      <td>39.50</td>
      <td>40.62</td>
      <td>41.43</td>
      <td>37.08</td>
      <td>35.24</td>
      <td>23.76</td>
      <td>47.73</td>
      <td>29.96</td>
      <td>32.94</td>
      <td>26.00</td>
      <td>37.88</td>
      <td>34.84</td>
      <td>32.67</td>
      <td>24.67</td>
      <td>33.18</td>
      <td>34.91</td>
      <td>21.73</td>
      <td>22.24</td>
      <td>34.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-7B-xtuner</td>
      <td>38.68</td>
      <td>38.22</td>
      <td>38.90</td>
      <td>40.03</td>
      <td>28.00</td>
      <td>40.25</td>
      <td>30.08</td>
      <td>44.08</td>
      <td>33.60</td>
      <td>32.49</td>
      <td>21.20</td>
      <td>40.91</td>
      <td>29.47</td>
      <td>40.40</td>
      <td>30.33</td>
      <td>38.59</td>
      <td>31.46</td>
      <td>23.85</td>
      <td>26.95</td>
      <td>36.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>XComposer2</td>
      <td>38.68</td>
      <td>39.20</td>
      <td>41.89</td>
      <td>37.59</td>
      <td>33.69</td>
      <td>40.79</td>
      <td>22.26</td>
      <td>45.87</td>
      <td>36.44</td>
      <td>32.94</td>
      <td>27.20</td>
      <td>58.59</td>
      <td>26.11</td>
      <td>36.40</td>
      <td>43.67</td>
      <td>37.29</td>
      <td>32.06</td>
      <td>23.46</td>
      <td>27.80</td>
      <td>32.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-InternLM-7b</td>
      <td>38.71</td>
      <td>39.11</td>
      <td>36.36</td>
      <td>36.54</td>
      <td>32.62</td>
      <td>38.10</td>
      <td>30.68</td>
      <td>46.53</td>
      <td>34.82</td>
      <td>28.19</td>
      <td>25.20</td>
      <td>48.99</td>
      <td>28.11</td>
      <td>40.53</td>
      <td>33.33</td>
      <td>36.00</td>
      <td>34.08</td>
      <td>26.73</td>
      <td>24.12</td>
      <td>29.71</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>TransCore-M</td>
      <td>38.86</td>
      <td>38.70</td>
      <td>40.74</td>
      <td>41.78</td>
      <td>20.77</td>
      <td>35.06</td>
      <td><u>34.74</u></td>
      <td>45.69</td>
      <td>32.39</td>
      <td>32.94</td>
      <td>24.40</td>
      <td>44.95</td>
      <td>31.05</td>
      <td>38.93</td>
      <td>27.00</td>
      <td>33.76</td>
      <td>33.86</td>
      <td>23.46</td>
      <td>25.49</td>
      <td>31.14</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.5</td>
      <td>38.86</td>
      <td>39.73</td>
      <td>43.84</td>
      <td>44.58</td>
      <td>34.00</td>
      <td>33.99</td>
      <td>31.28</td>
      <td>45.59</td>
      <td>33.20</td>
      <td>38.28</td>
      <td>32.40</td>
      <td>42.42</td>
      <td>31.89</td>
      <td>42.80</td>
      <td>27.00</td>
      <td>36.82</td>
      <td>34.76</td>
      <td>23.27</td>
      <td>24.72</td>
      <td>32.57</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2-Plus</td>
      <td>39.41</td>
      <td>40.79</td>
      <td>42.58</td>
      <td>42.31</td>
      <td>32.46</td>
      <td>37.03</td>
      <td>31.43</td>
      <td>47.49</td>
      <td>42.51</td>
      <td>35.01</td>
      <td>21.20</td>
      <td>50.51</td>
      <td>34.95</td>
      <td>42.93</td>
      <td>22.67</td>
      <td>42.47</td>
      <td>35.74</td>
      <td>22.31</td>
      <td>24.98</td>
      <td>28.29</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2</td>
      <td>39.52</td>
      <td>40.01</td>
      <td>41.66</td>
      <td>44.06</td>
      <td>27.38</td>
      <td>38.46</td>
      <td>34.29</td>
      <td>46.99</td>
      <td>33.60</td>
      <td>34.42</td>
      <td>21.20</td>
      <td>47.98</td>
      <td>30.63</td>
      <td>42.80</td>
      <td>27.67</td>
      <td>35.88</td>
      <td>35.59</td>
      <td><u>23.85</u></td>
      <td>24.98</td>
      <td>28.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-InternLM2-7b</td>
      <td>40.07</td>
      <td>40.45</td>
      <td>39.82</td>
      <td>37.94</td>
      <td>30.62</td>
      <td>35.24</td>
      <td>29.77</td>
      <td>48.97</td>
      <td>34.01</td>
      <td>25.96</td>
      <td>20.80</td>
      <td>53.03</td>
      <td>30.95</td>
      <td>42.67</td>
      <td>32.00</td>
      <td>39.88</td>
      <td>32.43</td>
      <td>21.73</td>
      <td>24.38</td>
      <td>38.00</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-1.3B</td>
      <td>40.25</td>
      <td>40.77</td>
      <td>38.55</td>
      <td>35.14</td>
      <td>38.92</td>
      <td>40.07</td>
      <td>27.97</td>
      <td>48.12</td>
      <td>35.63</td>
      <td>31.75</td>
      <td>22.80</td>
      <td>46.97</td>
      <td>40.74</td>
      <td>44.93</td>
      <td>31.00</td>
      <td>40.47</td>
      <td>33.33</td>
      <td>22.31</td>
      <td>21.39</td>
      <td>31.71</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V</td>
      <td>40.95</td>
      <td>41.05</td>
      <td>39.70</td>
      <td>46.50</td>
      <td>36.31</td>
      <td>39.36</td>
      <td>22.26</td>
      <td>48.09</td>
      <td>34.82</td>
      <td>35.76</td>
      <td>24.00</td>
      <td>45.45</td>
      <td>34.11</td>
      <td>44.80</td>
      <td>23.00</td>
      <td>44.47</td>
      <td>36.19</td>
      <td>21.15</td>
      <td>23.95</td>
      <td>35.14</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-7B</td>
      <td>41.73</td>
      <td>43.43</td>
      <td>38.43</td>
      <td>47.03</td>
      <td>42.31</td>
      <td>37.03</td>
      <td>26.47</td>
      <td>51.11</td>
      <td>33.20</td>
      <td>31.16</td>
      <td>26.00</td>
      <td>44.95</td>
      <td>36.00</td>
      <td>58.13</td>
      <td>36.33</td>
      <td>47.29</td>
      <td>34.91</td>
      <td>18.08</td>
      <td>25.49</td>
      <td><u>39.43</u></td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V2</td>
      <td>41.79</td>
      <td>42.54</td>
      <td>40.74</td>
      <td>43.01</td>
      <td>36.46</td>
      <td>37.57</td>
      <td>27.82</td>
      <td>51.08</td>
      <td>28.74</td>
      <td>29.08</td>
      <td>26.80</td>
      <td>47.47</td>
      <td>37.05</td>
      <td>46.40</td>
      <td>25.33</td>
      <td>46.59</td>
      <td>35.89</td>
      <td>22.31</td>
      <td>23.44</td>
      <td>31.71</td>
    </tr>
    <tr>
      <td colspan="21" style="text-align: center; background-color: #FFF0F0;">Proprietary LVLMs</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Claude3-Opus</td>
      <td>32.37</td>
      <td>32.44</td>
      <td>1.61</td>
      <td>39.51</td>
      <td>34.31</td>
      <td>31.66</td>
      <td>12.63</td>
      <td>39.26</td>
      <td>28.74</td>
      <td>30.86</td>
      <td>22.40</td>
      <td>37.37</td>
      <td>25.79</td>
      <td>41.07</td>
      <td>29.33</td>
      <td>33.18</td>
      <td>31.31</td>
      <td>21.35</td>
      <td>23.87</td>
      <td>4.00</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Qwen-VL-Max</td>
      <td>41.34</td>
      <td>42.16</td>
      <td>32.68</td>
      <td>44.58</td>
      <td>31.38</td>
      <td>40.79</td>
      <td>10.68</td>
      <td>50.53</td>
      <td>32.79</td>
      <td>44.36</td>
      <td>29.20</td>
      <td>51.52</td>
      <td>41.37</td>
      <td>58.00</td>
      <td>30.67</td>
      <td>41.65</td>
      <td>26.95</td>
      <td>25.00</td>
      <td>24.64</td>
      <td>39.14</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4V</td>
      <td>42.50</td>
      <td>44.08</td>
      <td>29.92</td>
      <td>48.95</td>
      <td>44.00</td>
      <td>37.39</td>
      <td>12.93</td>
      <td>52.88</td>
      <td>32.79</td>
      <td>44.21</td>
      <td><u>32.80</u></td>
      <td>63.64</td>
      <td>39.89</td>
      <td>54.13</td>
      <td>37.00</td>
      <td>50.59</td>
      <td>27.55</td>
      <td>23.08</td>
      <td>25.75</td>
      <td>37.43</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.0</td>
      <td>44.38</td>
      <td>44.93</td>
      <td><u>42.12</u></td>
      <td>45.10</td>
      <td>46.46</td>
      <td>37.57</td>
      <td>20.45</td>
      <td>53.29</td>
      <td>35.22</td>
      <td>36.94</td>
      <td>25.20</td>
      <td>51.01</td>
      <td>34.74</td>
      <td>59.60</td>
      <td>34.00</td>
      <td>50.00</td>
      <td><strong>36.64</strong></td>
      <td>23.65</td>
      <td>23.87</td>
      <td>35.43</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.5</td>
      <td><u>47.42</u></td>
      <td><u>48.36</u></td>
      <td><strong>43.50</strong></td>
      <td><u>56.12</u></td>
      <td><u>51.23</u></td>
      <td><u>47.58</u></td>
      <td>2.26</td>
      <td><u>55.33</u></td>
      <td><u>38.87</u></td>
      <td><u>48.07</u></td>
      <td>30.00</td>
      <td><strong>76.26</strong></td>
      <td><u>51.05</u></td>
      <td><strong>75.87</strong></td>
      <td><u>46.33</u></td>
      <td><u>62.24</u></td>
      <td>20.57</td>
      <td><strong>27.69</strong></td>
      <td><strong>30.54</strong></td>
      <td><strong>40.57</strong></td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4o</td>
      <td><strong>53.53</strong></td>
      <td><strong>53.96</strong></td>
      <td>38.32</td>
      <td><strong>61.01</strong></td>
      <td><strong>57.08</strong></td>
      <td><strong>49.02</strong></td>
      <td><strong>46.62</strong></td>
      <td><strong>61.45</strong></td>
      <td><strong>46.56</strong></td>
      <td><strong>56.38</strong></td>
      <td><strong>34.00</strong></td>
      <td><u>75.25</u></td>
      <td><strong>53.79</strong></td>
      <td><u>69.47</u></td>
      <td><strong>48.67</strong></td>
      <td><strong>65.88</strong></td>
      <td><u>33.93</u></td>
      <td>22.88</td>
      <td><u>29.51</u></td>
      <td><u>39.43</u></td>
    </tr>
  </tbody>
</table>
          <table id="table2" class="js-sort-table hidden">
            <tr>
              <th class="js-sort-string"><strong>Model name</strong></th>
              <th class="js-sort-number"><strong>Overall (val)</strong></th>
              <th class="js-sort-number"><strong>Overall (test)</strong></th>
              <th class="js-sort-number"><strong>CS</strong></th>
              <th class="js-sort-number"><strong>D</strong></th>
              <th class="js-sort-number"><strong>E</strong></th>
              <th class="js-sort-number"><strong>GH</strong></th>
              <th class="js-sort-number"><strong>GS</strong></th>
              <th class="js-sort-number"><strong>H</strong></th>
              <th class="js-sort-number"><strong>ID</strong></th>
              <th class="js-sort-number"><strong>LMP</strong></th>
              <th class="js-sort-number"><strong>NH</strong></th>
              <th class="js-sort-number"><strong>N</strong></th>
              <th class="js-sort-number"><strong>OG</strong></th>
              <th class="js-sort-number"><strong>OM</strong></th>
              <th class="js-sort-number"><strong>O</strong></th>
              <th class="js-sort-number"><strong>OS</strong></th>
              <th class="js-sort-number"><strong>ENT/HNS</strong></th>
              <th class="js-sort-number"><strong>PM</strong></th>
              <th class="js-sort-number"><strong>SM</strong></th>
              <th class="js-sort-number"><strong>U</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Random</td>
              <td>25.70</td>
              <td>25.94</td>
              <td>22.82</td>
              <td>25.19</td>
              <td>21.00</td>
              <td>25.97</td>
              <td>22.24</td>
              <td>24.45</td>
              <td>31.13</td>
              <td>28.99</td>
              <td>22.86</td>
              <td>24.00</td>
              <td>29.15</td>
              <td>27.77</td>
              <td>30.36</td>
              <td>25.92</td>
              <td>22.53</td>
              <td>24.74</td>
              <td>22.87</td>
              <td>29.19</td>
            </tr>
            <tr>
              <td colspan="21" style="text-align: center; background-color: #EFEFEF;">Medical Special Model</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedVInT</td>
              <td>2.29</td>
              <td>1.96</td>
              <td>0.24</td>
              <td>2.50</td>
              <td>1.00</td>
              <td>1.94</td>
              <td>1.09</td>
              <td>0.88</td>
              <td>3.31</td>
              <td>5.23</td>
              <td>1.14</td>
              <td>0.73</td>
              <td>0.00</td>
              <td>1.40</td>
              <td>4.44</td>
              <td>0.56</td>
              <td>0.00</td>
              <td>2.24</td>
              <td>0.64</td>
              <td>0.86</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Med-Flamingo</td>
              <td>12.74</td>
              <td>11.64</td>
              <td>11.76</td>
              <td>12.49</td>
              <td>10.00</td>
              <td>10.88</td>
              <td>9.33</td>
              <td>5.42</td>
              <td>7.28</td>
              <td>10.05</td>
              <td>12.00</td>
              <td>10.91</td>
              <td>12.88</td>
              <td>14.89</td>
              <td>15.37</td>
              <td>12.40</td>
              <td>13.43</td>
              <td>12.89</td>
              <td>14.92</td>
              <td>10.47</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>LLaVA-Med</td>
              <td>20.54</td>
              <td>19.60</td>
              <td>26.12</td>
              <td>20.20</td>
              <td>29.00</td>
              <td>20.31</td>
              <td>16.30</td>
              <td>18.46</td>
              <td>15.23</td>
              <td>21.84</td>
              <td>20.86</td>
              <td>16.73</td>
              <td>21.69</td>
              <td>19.23</td>
              <td>20.18</td>
              <td>18.38</td>
              <td>20.99</td>
              <td>16.87</td>
              <td>20.49</td>
              <td>21.55</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Qilin-Med-VL-Chat</td>
              <td>22.34</td>
              <td>22.06</td>
              <td>12.94</td>
              <td>21.06</td>
              <td>15.50</td>
              <td>22.09</td>
              <td>18.98</td>
              <td>17.33</td>
              <td>17.88</td>
              <td>22.92</td>
              <td>31.14</td>
              <td>29.82</td>
              <td>20.00</td>
              <td>21.83</td>
              <td>25.55</td>
              <td>19.07</td>
              <td>14.81</td>
              <td>29.42</td>
              <td>22.17</td>
              <td>22.29</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>RadFM</td>
              <td>22.95</td>
              <td>22.93</td>
              <td>24.24</td>
              <td>23.02</td>
              <td>20.00</td>
              <td>20.59</td>
              <td>20.83</td>
              <td>19.49</td>
              <td>28.48</td>
              <td>24.42</td>
              <td>18.00</td>
              <td>32.00</td>
              <td>16.95</td>
              <td>26.90</td>
              <td>26.25</td>
              <td>18.26</td>
              <td>26.54</td>
              <td>25.19</td>
              <td>23.74</td>
              <td>20.20</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedDr</td>
              <td>41.95</td>
              <td>43.69</td>
              <td>53.18</td>
              <td>45.28</td>
              <td>33.00</td>
              <td>44.78</td>
              <td>28.03</td>
              <td>29.91</td>
              <td>47.68</td>
              <td>35.22</td>
              <td>38.29</td>
              <td>78.55</td>
              <td>25.08</td>
              <td>49.53</td>
              <td>45.31</td>
              <td>52.09</td>
              <td>48.61</td>
              <td>52.36</td>
              <td>54.21</td>
              <td>39.90</td>
            </tr>
            <tr>
              <td colspan="21" style="text-align: center; background-color: #FFF3E4;">Open-Source LVLMs</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>CogVLM-grounding-generalist</td>
              <td>5.20</td>
              <td>5.66</td>
              <td>6.59</td>
              <td>7.27</td>
              <td>4.50</td>
              <td>4.94</td>
              <td>3.58</td>
              <td>4.44</td>
              <td>5.96</td>
              <td>2.66</td>
              <td>19.14</td>
              <td>17.82</td>
              <td>7.80</td>
              <td>7.94</td>
              <td>5.00</td>
              <td>5.36</td>
              <td>5.40</td>
              <td>7.86</td>
              <td>4.59</td>
              <td>2.34</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer</td>
              <td>8.92</td>
              <td>7.67</td>
              <td>13.18</td>
              <td>2.71</td>
              <td>5.00</td>
              <td>5.33</td>
              <td>4.35</td>
              <td>10.88</td>
              <td>3.31</td>
              <td>6.40</td>
              <td>4.00</td>
              <td>25.09</td>
              <td>6.44</td>
              <td>9.15</td>
              <td>9.95</td>
              <td>8.91</td>
              <td>4.01</td>
              <td>8.11</td>
              <td>9.87</td>
              <td>5.54</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>PandaGPT 13B</td>
              <td>16.69</td>
              <td>16.27</td>
              <td>17.41</td>
              <td>12.70</td>
              <td>17.00</td>
              <td>17.20</td>
              <td>12.68</td>
              <td>15.42</td>
              <td>23.84</td>
              <td>14.70</td>
              <td>14.86</td>
              <td>10.55</td>
              <td>8.81</td>
              <td>14.29</td>
              <td>24.75</td>
              <td>16.26</td>
              <td>17.13</td>
              <td>18.07</td>
              <td>12.07</td>
              <td>13.92</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Flamingo v2</td>
              <td>25.58</td>
              <td>26.34</td>
              <td>28.47</td>
              <td>26.06</td>
              <td>18.50</td>
              <td>28.58</td>
              <td>21.11</td>
              <td>24.24</td>
              <td>29.14</td>
              <td>28.07</td>
              <td>13.43</td>
              <td>29.45</td>
              <td>22.37</td>
              <td>28.17</td>
              <td>31.85</td>
              <td>23.12</td>
              <td>27.78</td>
              <td>23.54</td>
              <td>27.57</td>
              <td>29.19</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>VisualGLM-6B</td>
              <td>29.58</td>
              <td>30.45</td>
              <td>52.71</td>
              <td>25.95</td>
              <td>14.00</td>
              <td>31.69</td>
              <td>22.06</td>
              <td>25.17</td>
              <td>30.46</td>
              <td>25.50</td>
              <td>30.29</td>
              <td>59.27</td>
              <td>15.93</td>
              <td>29.97</td>
              <td>37.79</td>
              <td>30.09</td>
              <td>23.61</td>
              <td>32.85</td>
              <td>38.19</td>
              <td>23.03</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Idefics-9B-Instruct</td>
              <td>29.74</td>
              <td>31.13</td>
              <td>19.76</td>
              <td>33.98</td>
              <td>21.00</td>
              <td>30.08</td>
              <td>24.46</td>
              <td>26.66</td>
              <td>50.33</td>
              <td>28.74</td>
              <td>36.00</td>
              <td>58.55</td>
              <td>36.27</td>
              <td>29.64</td>
              <td>36.76</td>
              <td>36.07</td>
              <td>24.38</td>
              <td>31.36</td>
              <td>32.04</td>
              <td>29.19</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InstructBLIP-7B</td>
              <td>31.80</td>
              <td>30.95</td>
              <td>27.06</td>
              <td>28.99</td>
              <td>17.50</td>
              <td>34.24</td>
              <td>21.78</td>
              <td>25.84</td>
              <td>43.05</td>
              <td>29.15</td>
              <td>19.14</td>
              <td>53.09</td>
              <td>27.46</td>
              <td>28.64</td>
              <td>31.99</td>
              <td>34.58</td>
              <td>30.25</td>
              <td>30.76</td>
              <td>41.09</td>
              <td>31.28</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Mini-Gemini-7B</td>
              <td>32.17</td>
              <td>31.09</td>
              <td>34.59</td>
              <td>39.63</td>
              <td>23.50</td>
              <td>35.74</td>
              <td>23.46</td>
              <td>19.80</td>
              <td>41.06</td>
              <td>25.91</td>
              <td>40.86</td>
              <td>56.00</td>
              <td>19.32</td>
              <td>21.63</td>
              <td>35.73</td>
              <td>35.83</td>
              <td>33.95</td>
              <td>40.57</td> 
              <td>57</td>
      <td>29.14</td>
      <td>29.56</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MMAlaya</td>
      <td>32.19</td>
      <td>32.30</td>
      <td>71.06</td>
      <td>37.68</td>
      <td>38.00</td>
      <td>28.30</td>
      <td>27.40</td>
      <td>27.64</td>
      <td>51.66</td>
      <td>32.39</td>
      <td>28.86</td>
      <td>83.64</td>
      <td>29.49</td>
      <td>27.37</td>
      <td>35.92</td>
      <td>36.70</td>
      <td>20.99</td>
      <td>27.53</td>
      <td>29.43</td>
      <td>28.08</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Qwen-VL</td>
      <td>34.80</td>
      <td>36.05</td>
      <td>39.53</td>
      <td>41.59</td>
      <td>40.50</td>
      <td>28.69</td>
      <td>20.74</td>
      <td>26.77</td>
      <td>45.03</td>
      <td>28.82</td>
      <td>56.57</td>
      <td>73.09</td>
      <td>39.32</td>
      <td>41.39</td>
      <td>39.23</td>
      <td>43.36</td>
      <td>33.64</td>
      <td>35.74</td>
      <td>45.15</td>
      <td>42.73</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Yi-VL-6B</td>
      <td>34.82</td>
      <td>34.31</td>
      <td>39.76</td>
      <td>43.76</td>
      <td>56.00</td>
      <td>27.30</td>
      <td>25.91</td>
      <td>27.23</td>
      <td>45.70</td>
      <td>32.56</td>
      <td>44.29</td>
      <td>65.45</td>
      <td>47.46</td>
      <td>36.38</td>
      <td>39.00</td>
      <td>35.39</td>
      <td>25.46</td>
      <td>29.77</td>
      <td>39.06</td>
      <td>35.22</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLaVA-NeXT-vicuna-7B</td>
      <td>34.86</td>
      <td>35.42</td>
      <td>40.00</td>
      <td>37.13</td>
      <td>51.60</td>
      <td>31.82</td>
      <td>29.15</td>
      <td>26.18</td>
      <td>49.01</td>
      <td>31.06</td>
      <td>32.94</td>
      <td>65.33</td>
      <td>28.44</td>
      <td>35.98</td>
      <td>43.21</td>
      <td>38.71</td>
      <td>26.87</td>
      <td>40.02</td>
      <td>36.47</td>
      <td>32.36</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Qwen-VL-Chat</td>
      <td>35.07</td>
      <td>36.96</td>
      <td>36.47</td>
      <td>39.63</td>
      <td>36.50</td>
      <td>27.08</td>
      <td>20.79</td>
      <td>27.64</td>
      <td><u>60.93</u></td>
      <td>30.23</td>
      <td>52.57</td>
      <td>70.55</td>
      <td>37.29</td>
      <td>47.13</td>
      <td>39.37</td>
      <td>46.67</td>
      <td>34.57</td>
      <td>37.63</td>
      <td>47.88</td>
      <td>39.90</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>CogVLM-Chat</td>
      <td>35.23</td>
      <td>36.08</td>
      <td>30.59</td>
      <td>38.98</td>
      <td>42.50</td>
      <td>31.41</td>
      <td>26.22</td>
      <td>23.62</td>
      <td>47.02</td>
      <td>34.22</td>
      <td>51.43</td>
      <td>56.00</td>
      <td>32.54</td>
      <td>44.13</td>
      <td>38.67</td>
      <td>37.94</td>
      <td>30.86</td>
      <td>41.11</td>
      <td>45.91</td>
      <td>29.19</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Monkey</td>
      <td>35.48</td>
      <td>36.39</td>
      <td>38.59</td>
      <td>39.52</td>
      <td>35.00</td>
      <td>29.74</td>
      <td>20.97</td>
      <td>25.73</td>
      <td>52.98</td>
      <td>28.90</td>
      <td>48.29</td>
      <td>68.00</td>
      <td>34.24</td>
      <td>41.46</td>
      <td>40.78</td>
      <td>45.23</td>
      <td>31.79</td>
      <td>39.27</td>
      <td>45.91</td>
      <td>42.49</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>mPLUG-Owl2</td>
      <td>35.62</td>
      <td>36.21</td>
      <td>47.76</td>
      <td>40.50</td>
      <td>41.00</td>
      <td>33.46</td>
      <td>27.22</td>
      <td>28.16</td>
      <td>51.66</td>
      <td>33.14</td>
      <td>38.86</td>
      <td>68.73</td>
      <td>16.27</td>
      <td>38.58</td>
      <td>43.34</td>
      <td>35.70</td>
      <td>27.78</td>
      <td>41.61</td>
      <td>39.76</td>
      <td>30.91</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>ShareCaptioner</td>
      <td>36.37</td>
      <td>36.19</td>
      <td>37.88</td>
      <td>35.50</td>
      <td>45.50</td>
      <td>35.63</td>
      <td>25.54</td>
      <td>28.16</td>
      <td>56.29</td>
      <td>31.15</td>
      <td>27.14</td>
      <td>64.00</td>
      <td>35.59</td>
      <td>38.52</td>
      <td>39.65</td>
      <td>38.57</td>
      <td>30.56</td>
      <td>44.05</td>
      <td>36.68</td>
      <td>40.15</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Emu2-Chat</td>
      <td>36.50</td>
      <td>37.59</td>
      <td>27.53</td>
      <td>35.83</td>
      <td>27.50</td>
      <td>34.41</td>
      <td>28.49</td>
      <td>29.35</td>
      <td>60.26</td>
      <td>36.63</td>
      <td>34.00</td>
      <td>64.73</td>
      <td>28.81</td>
      <td>44.79</td>
      <td>43.20</td>
      <td>37.69</td>
      <td>37.50</td>
      <td>41.86</td>
      <td>43.18</td>
      <td>35.34</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>XComposer2-4KHD</td>
      <td>36.66</td>
      <td>38.54</td>
      <td>48.00</td>
      <td>40.17</td>
      <td>75.50</td>
      <td>36.46</td>
      <td>28.80</td>
      <td>28.11</td>
      <td>49.67</td>
      <td>35.96</td>
      <td>50.29</td>
      <td>69.45</td>
      <td>38.64</td>
      <td>40.45</td>
      <td>43.86</td>
      <td>39.63</td>
      <td>29.94</td>
      <td>43.26</td>
      <td>34.13</td>
      <td>42.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>ShareGPT4V-7B</td>
      <td>36.71</td>
      <td>36.70</td>
      <td>43.76</td>
      <td>39.09</td>
      <td>48.50</td>
      <td>37.24</td>
      <td>27.90</td>
      <td>23.88</td>
      <td>49.01</td>
      <td>30.40</td>
      <td>46.29</td>
      <td>60.73</td>
      <td>29.15</td>
      <td>44.46</td>
      <td>44.56</td>
      <td>37.57</td>
      <td>30.40</td>
      <td>38.03</td>
      <td>35.98</td>
      <td>36.95</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLaVA-NeXT-mistral-7B</td>
      <td>37.20</td>
      <td>37.16</td>
      <td>42.96</td>
      <td>40.17</td>
      <td>46.40</td>
      <td>37.84</td>
      <td>28.53</td>
      <td>23.76</td>
      <td>52.32</td>
      <td>31.81</td>
      <td>46.59</td>
      <td>73.00</td>
      <td>21.25</td>
      <td>47.08</td>
      <td>42.61</td>
      <td>33.37</td>
      <td>22.75</td>
      <td>46.94</td>
      <td>37.45</td>
      <td>33.48</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-13b-xtuner</td>
      <td>37.82</td>
      <td>38.74</td>
      <td>43.06</td>
      <td>39.20</td>
      <td>43.50</td>
      <td>42.01</td>
      <td>26.36</td>
      <td>26.41</td>
      <td>48.34</td>
      <td>35.55</td>
      <td>38.29</td>
      <td>70.55</td>
      <td>38.64</td>
      <td>51.60</td>
      <td>42.08</td>
      <td>34.70</td>
      <td>34.41</td>
      <td>43.90</td>
      <td>39.35</td>
      <td>41.26</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>OmniLMM-12B</td>
      <td>37.89</td>
      <td>39.30</td>
      <td>39.53</td>
      <td>37.46</td>
      <td>41.50</td>
      <td>36.18</td>
      <td>27.36</td>
      <td>28.00</td>
      <td><u>60.93</u></td>
      <td>37.46</td>
      <td>55.43</td>
      <td>80.00</td>
      <td>31.19</td>
      <td>35.71</td>
      <td>44.89</td>
      <td>42.49</td>
      <td>28.24</td>
      <td>43.80</td>
      <td>51.19</td>
      <td>42.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.1</td>
      <td>38.16</td>
      <td>39.41</td>
      <td>45.88</td>
      <td>40.07</td>
      <td>56.00</td>
      <td>34.30</td>
      <td>26.68</td>
      <td>26.20</td>
      <td>52.32</td>
      <td>37.79</td>
      <td>45.14</td>
      <td>64.00</td>
      <td>35.93</td>
      <td>52.74</td>
      <td>44.14</td>
      <td>40.56</td>
      <td>39.51</td>
      <td>41.16</td>
      <td>45.56</td>
      <td>35.84</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-7B</td>
      <td>38.23</td>
      <td>37.96</td>
      <td>42.35</td>
      <td>37.57</td>
      <td>44.50</td>
      <td>36.13</td>
      <td>27.99</td>
      <td>24.91</td>
      <td>49.01</td>
      <td>31.31</td>
      <td>34.00</td>
      <td>68.36</td>
      <td>27.12</td>
      <td>45.39</td>
      <td>42.46</td>
      <td>42.80</td>
      <td>33.80</td>
      <td>44.20</td>
      <td>41.21</td>
      <td>38.92</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Monkey-Chat</td>
      <td>38.39</td>
      <td>39.50</td>
      <td>43.53</td>
      <td>40.28</td>
      <td>40.00</td>
      <td>33.30</td>
      <td>23.28</td>
      <td>29.09</td>
      <td>54.97</td>
      <td>29.73</td>
      <td>55.71</td>
      <td>72.36</td>
      <td>35.25</td>
      <td>50.53</td>
      <td>42.41</td>
      <td>45.98</td>
      <td>33.49</td>
      <td>42.66</td>
      <td>50.15</td>
      <td>44.83</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-V1.5-7B-xtuner</td>
      <td>38.68</td>
      <td>38.22</td>
      <td>51.53</td>
      <td>35.07</td>
      <td>31.00</td>
      <td>38.07</td>
      <td>31.52</td>
      <td>29.04</td>
      <td>58.94</td>
      <td>36.79</td>
      <td>28.29</td>
      <td>69.09</td>
      <td>29.15</td>
      <td>50.80</td>
      <td>39.89</td>
      <td>40.12</td>
      <td>27.78</td>
      <td>40.82</td>
      <td>39.12</td>
      <td>36.08</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>XComposer2</td>
      <td>38.68</td>
      <td>39.20</td>
      <td>32.71</td>
      <td>42.13</td>
      <td>70.50</td>
      <td>33.13</td>
      <td>29.62</td>
      <td>27.02</td>
      <td>54.30</td>
      <td>34.05</td>
      <td>23.14</td>
      <td>83.64</td>
      <td>39.66</td>
      <td>46.53</td>
      <td>44.23</td>
      <td>45.73</td>
      <td>28.86</td>
      <td>45.55</td>
      <td>41.32</td>
      <td>41.87</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-InternLM-7b</td>
      <td>38.71</td>
      <td>39.11</td>
      <td>44.94</td>
      <td>39.85</td>
      <td>33.50</td>
      <td>43.06</td>
      <td>27.54</td>
      <td>27.08</td>
      <td>52.98</td>
      <td>34.22</td>
      <td>31.14</td>
      <td>79.64</td>
      <td>37.97</td>
      <td>50.67</td>
      <td>42.41</td>
      <td>39.69</td>
      <td>36.73</td>
      <td>37.63</td>
      <td>46.72</td>
      <td>39.78</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>TransCore-M</td>
      <td>38.86</td>
      <td>38.70</td>
      <td>39.06</td>
      <td>43.87</td>
      <td>24.50</td>
      <td>40.18</td>
      <td>29.08</td>
      <td>30.79</td>
      <td>52.98</td>
      <td>32.48</td>
      <td>38.86</td>
      <td>66.91</td>
      <td>42.37</td>
      <td>42.79</td>
      <td>44.75</td>
      <td>40.44</td>
      <td>36.73</td>
      <td>34.00</td>
      <td>47.19</td>
      <td>35.71</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.5</td>
      <td>38.86</td>
      <td>39.73</td>
      <td>36.47</td>
      <td>44.84</td>
      <td>53.50</td>
      <td>37.07</td>
      <td>26.63</td>
      <td>31.61</td>
      <td>60.26</td>
      <td>34.14</td>
      <td>36.29</td>
      <td>67.27</td>
      <td>37.63</td>
      <td>55.21</td>
      <td>47.13</td>
      <td>38.69</td>
      <td>41.98</td>
      <td>39.17</td>
      <td>37.55</td>
      <td>41.26</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2-Plus</td>
      <td>39.41</td>
      <td>40.79</td>
      <td>51.06</td>
      <td>43.54</td>
      <td>60.00</td>
      <td>39.07</td>
      <td>29.39</td>
      <td><u>31.82</u></td>
      <td>50.99</td>
      <td>37.54</td>
      <td>54.00</td>
      <td>79.64</td>
      <td>30.17</td>
      <td>50.87</td>
      <td>43.72</td>
      <td>37.88</td>
      <td>36.88</td>
      <td>42.61</td>
      <td>43.53</td>
      <td>38.55</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2</td>
      <td>39.52</td>
      <td>40.01</td>
      <td>40.71</td>
      <td>46.25</td>
      <td>77.50</td>
      <td>31.52</td>
      <td>26.36</td>
      <td>31.10</td>
      <td>50.33</td>
      <td>36.96</td>
      <td>52.00</td>
      <td>80.00</td>
      <td>31.19</td>
      <td>45.46</td>
      <td>43.20</td>
      <td>40.06</td>
      <td>34.10</td>
      <td>44.40</td>
      <td>46.66</td>
      <td><u>42.36</u></td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-InternLM2-7b</td>
      <td>40.07</td>
      <td>40.45</td>
      <td>43.53</td>
      <td>40.72</td>
      <td>60.50</td>
      <td>34.74</td>
      <td>30.12</td>
      <td>27.44</td>
      <td>51.66</td>
      <td>33.39</td>
      <td>50.86</td>
      <td>74.55</td>
      <td>26.44</td>
      <td>49.13</td>
      <td>42.74</td>
      <td>43.12</td>
      <td>31.94</td>
      <td>50.87</td>
      <td>47.01</td>
      <td>39.04</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-1.3B</td>
      <td>40.25</td>
      <td>40.77</td>
      <td>56.71</td>
      <td>37.13</td>
      <td>27.00</td>
      <td>45.73</td>
      <td>28.40</td>
      <td>27.85</td>
      <td>52.32</td>
      <td>35.96</td>
      <td>45.43</td>
      <td>71.64</td>
      <td>45.42</td>
      <td>50.20</td>
      <td>41.66</td>
      <td>47.48</td>
      <td>37.81</td>
      <td>43.90</td>
      <td>45.50</td>
      <td>33.50</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V</td>
      <td>40.95</td>
      <td>41.05</td>
      <td>28.47</td>
      <td>42.02</td>
      <td>40.00</td>
      <td>42.79</td>
      <td>28.80</td>
      <td>28.62</td>
      <td>46.36</td>
      <td>36.30</td>
      <td>40.00</td>
      <td>67.27</td>
      <td>31.53</td>
      <td>42.46</td>
      <td>44.04</td>
      <td>50.28</td>
      <td>37.50</td>
      <td>51.92</td>
      <td>52.29</td>
      <td>27.22</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-7B</td>
      <td>41.73</td>
      <td>43.43</td>
      <td>60.00</td>
      <td>43.97</td>
      <td>47.50</td>
      <td>45.12</td>
      <td>28.22</td>
      <td>31.20</td>
      <td>46.36</td>
      <td>32.97</td>
      <td>52.29</td>
      <td>67.64</td>
      <td><strong>61.36</strong></td>
      <td>49.27</td>
      <td>44.23</td>
      <td>49.97</td>
      <td>52.78</td>
      <td>45.00</td>
      <td>53.63</td>
      <td>38.79</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V2</td>
      <td>41.79</td>
      <td>42.54</td>
      <td>37.88</td>
      <td>43.65</td>
      <td>35.50</td>
      <td>42.67</td>
      <td>26.49</td>
      <td>29.24</td>
      <td>37.75</td>
      <td>33.31</td>
      <td><u>59.71</u></td>
      <td>67.27</td>
      <td>38.64</td>
      <td>50.87</td>
      <td>42.64</td>
      <td>50.59</td>
      <td>40.90</td>
      <td>51.07</td>
      <td>57.81</td>
      <td>35.10</td>
    </tr>
    <tr>
      <td colspan="21" style="text-align: center; background-color: #FFF0F0;">Proprietary LVLMs</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Claude3-Opus</td>
      <td>32.37</td>
      <td>32.44</td>
      <td>38.59</td>
      <td>34.42</td>
      <td>43.50</td>
      <td>27.97</td>
      <td>22.96</td>
      <td>23.62</td>
      <td>52.32</td>
      <td>25.42</td>
      <td>25.14</td>
      <td>66.91</td>
      <td>15.93</td>
      <td>35.25</td>
      <td>41.06</td>
      <td>36.07</td>
      <td>37.50</td>
      <td>40.67</td>
      <td>35.40</td>
      <td>34.24</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Qwen-VL-Max</td>
      <td>41.34</td>
      <td>42.16</td>
      <td>50.59</td>
      <td>47.23</td>
      <td><strong>74.00</strong></td>
      <td>40.68</td>
      <td>29.03</td>
      <td>26.71</td>
      <td>58.94</td>
      <td>34.05</td>
      <td>62.29</td>
      <td>85.45</td>
      <td>27.80</td>
      <td>44.39</td>
      <td>43.90</td>
      <td>42.99</td>
      <td>48.61</td>
      <td>49.38</td>
      <td>51.13</td>
      <td>40.52</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4V</td>
      <td>42.50</td>
      <td>44.08</td>
      <td><u>64.00</u></td>
      <td>44.95</td>
      <td>58.50</td>
      <td>42.45</td>
      <td>30.03</td>
      <td>29.40</td>
      <td>58.28</td>
      <td>32.31</td>
      <td>54.57</td>
      <td>83.27</td>
      <td>37.63</td>
      <td>48.26</td>
      <td>49.04</td>
      <td>48.41</td>
      <td>44.60</td>
      <td>51.87</td>
      <td>53.98</td>
      <td>40.89</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.0</td>
      <td>44.38</td>
      <td>44.93</td>
      <td>57.41</td>
      <td>46.25</td>
      <td>57.50</td>
      <td>36.40</td>
      <td>28.67</td>
      <td>27.80</td>
      <td>45.03</td>
      <td><u>38.21</u></td>
      <td>58.57</td>
      <td>86.55</td>
      <td>40.68</td>
      <td><u>51.74</u></td>
      <td>47.45</td>
      <td>55.64</td>
      <td>50.46</td>
      <td>47.83</td>
      <td><u>61.58</u></td>
      <td>41.87</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.5</td>
      <td><u>47.42</u></td>
      <td><u>48.36</u></td>
      <td>55.29</td>
      <td><strong>50.81</strong></td>
      <td>54.00</td>
      <td><u>51.05</u></td>
      <td><strong>36.59</strong></td>
      <td>29.86</td>
      <td>56.95</td>
      <td>36.88</td>
      <td>58.00</td>
      <td><u>88.00</u></td>
      <td><u>47.46</u></td>
      <td>48.13</td>
      <td><u>51.19</u></td>
      <td><u>56.88</u></td>
      <td><u>64.51</u></td>
      <td><u>56.50</u></td>
      <td>59.78</td>
      <td>31.65</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4o</td>
      <td><strong>53.53</strong></td>
      <td><strong>53.96</strong></td>
      <td><strong>66.82</strong></td>
      <td><u>48.53</u></td>
      <td><u>64.50</u></td>
      <td><strong>55.94</strong></td>
      <td><u>35.10</u></td>
      <td><strong>48.53</strong></td>
      <td><strong>74.17</strong></td>
      <td><strong>43.52</strong></td>
      <td><strong>64.57</strong></td>
      <td><strong>91.64</strong></td>
      <td>37.63</td>
      <td><strong>57.88</strong></td>
      <td><strong>55.21</strong></td>
      <td><strong>62.80</strong></td>
      <td><strong>66.98</strong></td>
      <td><strong>58.39</strong></td>
      <td><strong>64.60</strong></td>
      <td><strong>46.18</strong></td>
    </tr>
  </tbody>
</table>
          <table id="table3" class="js-sort-table hidden">
            <thead>
              <tr>
                <th class="js-sort-string"><strong>Model name</strong></th>
                <th class="js-sort-string"><strong>Size</strong></th>
                <th class="js-sort-number"><strong>Overall (val)</strong></th>
                <th class="js-sort-number"><strong>Overall (test)</strong></th>
                <th class="js-sort-number"><strong>Seg C</strong></th>
                <th class="js-sort-number"><strong>Seg M</strong></th>
                <th class="js-sort-number"><strong>2D Cls update</strong></th>
                <th class="js-sort-number"><strong>2D Det</strong></th>
                <th class="js-sort-number"><strong>2D Mcls_acc</strong></th>
                <th class="js-sort-number"><strong>2D Mcls_recall</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Random</td>
                <td>-</td>
                <td>25.70</td>
                <td>25.88</td>
                <td>22.19</td>
                <td>22.91</td>
                <td>28.93</td>
                <td>24.55</td>
                <td>45.85</td>
                <td>57.02</td>
              </tr>
              <tr>
                <td colspan="10" style="text-align: center; background-color: #EFEFEF;">Medical Special Model</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>MedVInT</td>
                <td>-</td>
                <td>2.29</td>
                <td>1.98</td>
                <td>0.82</td>
                <td>0.25</td>
                <td>3.48</td>
                <td>0.12</td>
                <td>0.05</td>
                <td>0.02</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>Med-Flamingo</td>
                <td>8.3B</td>
                <td>12.74</td>
                <td>11.75</td>
                <td>11.95</td>
                <td>11.94</td>
                <td>11.92</td>
                <td>9.15</td>
                <td>46.10</td>
                <td>50.19</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>LLaVA-Med</td>
                <td>-</td>
                <td>20.54</td>
                <td>19.83</td>
                <td>18.45</td>
                <td>18.97</td>
                <td>21.15</td>
                <td>17.14</td>
                <td>45.84</td>
                <td>41.19</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>Qilin-Med-VL-Chat</td>
                <td>-</td>
                <td>22.34</td>
                <td>22.06</td>
                <td>19.84</td>
                <td>20.30</td>
                <td>23.80</td>
                <td>21.87</td>
                <td>44.50</td>
                <td>33.90</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>RadFM</td>
                <td>14B</td>
                <td>22.95</td>
                <td>22.93</td>
                <td>20.43</td>
                <td>20.27</td>
                <td>25.71</td>
                <td>18.83</td>
                <td>40.98</td>
                <td>57.45</td>
              </tr>
              <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td>MedDr</td>
                <td>40B</td>
                <td>41.95</td>
                <td>43.18</td>
                <td>42.55</td>
                <td>44.03</td>
                <td>45.08</td>
                <td>28.10</td>
                <td>48.09</td>
                <td>23.38</td>
              </tr>
              <tr>
                <td colspan="10" style="text-align: center; background-color: #FFF3E4;">Open-Source LVLMs</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>CogVLM-grounding-generalist</td>
                <td>17B</td>
                <td>5.20</td>
                <td>5.39</td>
                <td>6.80</td>
                <td>5.51</td>
                <td>5.11</td>
                <td>2.57</td>
                <td>46.24</td>
                <td>49.82</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>XComposer</td>
                <td>8B</td>
                <td>8.92</td>
                <td>7.71</td>
                <td>8.87</td>
                <td>6.24</td>
                <td>8.02</td>
                <td>6.30</td>
                <td>31.45</td>
                <td>23.68</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>PandaGPT 13B</td>
                <td>13B</td>
                <td>16.69</td>
                <td>15.94</td>
                <td>19.25</td>
                <td>18.88</td>
                <td>13.74</td>
                <td>12.24</td>
                <td>41.22</td>
                <td>49.95</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Flamingo v2</td>
                <td>9B</td>
                <td>25.58</td>
                <td>26.23</td>
                <td>22.52</td>
                <td>22.48</td>
                <td>30.12</td>
                <td>21.17</td>
                <td>41.80</td>
                <td>19.17</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>VisualGLM-6B</td>
                <td>7.8B</td>
                <td>29.58</td>
                <td>30.20</td>
                <td>27.30</td>
                <td>27.31</td>
                <td>33.75</td>
                <td>22.16</td>
                <td>43.08</td>
                <td>35.22</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Idefics-9B-Instruct</td>
                <td>9B</td>
                <td>29.74</td>
                <td>30.81</td>
                <td>25.50</td>
                <td>25.21</td>
                <td>36.45</td>
                <td>23.85</td>
                <td>43.47</td>
                <td>46.02</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InstructBLIP-7B</td>
                <td>8B</td>
                <td>31.80</td>
                <td>31.00</td>
                <td>29.12</td>
                <td>21.77</td>
                <td>36.71</td>
                <td>24.08</td>
                <td>39.43</td>
                <td>23.79</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Mini-Gemini-7B</td>
                <td>7B</td>
                <td>32.17</td>
                <td>31.22</td>
                <td>32.13</td>
                <td>32.92</td>
                <td>30.72</td>
                <td>26.53</td>
                <td>45.38</td>
                <td>57.99</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>MMAlaya</td>
                <td>7.8B</td>
                <td>32.19</td>
                <td>32.02</td>
                <td>29.33</td>
                <td>30.22</td>
                <td>35.02</td>
                <td>24.02</td>
                <td>48.43</td>
                <td>20.93</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Qwen-VL</td>
                <td>9.6B</td>
                <td>34.80</td>
                <td>35.55</td>
                <td>33.20</td>
                <td>33.43</td>
                <td>38.95</td>
                <td>24.49</td>
                <td>44.95</td>
                <td>56.97</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Yi-VL-6B</td>
                <td>6.6B</td>
                <td>34.82</td>
                <td>34.00</td>
                <td>31.42</td>
                <td>32.26</td>
                <td>37.15</td>
                <td>24.31</td>
                <td>50.25</td>
                <td>44.32</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLaVA-NeXT-vicuna-7B</td>
                <td>7.1B</td>
                <td>34.86</td>
                <td>35.59</td>
                <td>33.06</td>
                <td>32.95</td>
                <td>38.96</td>
                <td>27.06</td>
                <td>44.75</td>
                <td>42.45</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Qwen-VL-Chat</td>
                <td>9.6B</td>
                <td>35.07</td>
                <td>36.35</td>
                <td>34.45</td>
                <td>35.20</td>
                <td>39.55</td>
                <td>22.04</td>
                <td>42.88</td>
                <td><u>81.23</u></td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>CogVLM-Chat</td>
                <td>17B</td>
                <td>35.23</td>
                <td>35.83</td>
                <td>34.13</td>
                <td>34.49</td>
                <td>38.55</td>
                <td>25.25</td>
                <td>47.09</td>
                <td><strong>90.26</strong></td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Monkey</td>
                <td>9.8B</td>
                <td>35.48</td>
                <td>35.92</td>
                <td>33.18</td>
                <td>34.01</td>
                <td>39.32</td>
                <td>25.42</td>
                <td>44.57</td>
                <td>42.35</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>mPLUG-Owl2</td>
                <td>8.2B</td>
                <td>35.62</td>
                <td>35.89</td>
                <td>33.68</td>
                <td>34.74</td>
                <td>38.80</td>
                <td>24.90</td>
                <td>42.59</td>
                <td>41.84</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>ShareCaptioner</td>
                <td>8B</td>
                <td>36.37</td>
                <td>36.07</td>
                <td>34.74</td>
                <td>35.93</td>
                <td>38.25</td>
                <td>24.37</td>
                <td>40.00</td>
                <td>16.95</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Emu2-Chat</td>
                <td>37B</td>
                <td>36.50</td>
                <td>35.54</td>
                <td>36.54</td>
                <td>27.62</td>
                <td>39.57</td>
                <td>27.76</td>
                <td>44.29</td>
                <td>37.65</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>XComposer2-4KHD</td>
                <td>7B</td>
                <td>36.66</td>
                <td>37.93</td>
                <td>36.84</td>
                <td>38.02</td>
                <td>39.84</td>
                <td>26.65</td>
                <td>48.83</td>
                <td>44.08</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>ShareGPT4V-7B</td>
                <td>7.2B</td>
                <td>36.71</td>
                <td>36.52</td>
                <td>34.74</td>
                <td>35.15</td>
                <td>39.24</td>
                <td>26.18</td>
                <td>46.11</td>
                <td>43.52</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLaVA-NeXT-mistral-7B</td>
                <td>7.6B</td>
                <td>37.20</td>
                <td>37.02</td>
                <td>36.29</td>
                <td>35.20</td>
                <td>39.34</td>
                <td>27.87</td>
                <td>44.05</td>
                <td>47.70</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLAVA-V1.5-13b-xtuner</td>
                <td>13.4B</td>
                <td>37.82</td>
                <td>38.27</td>
                <td>38.29</td>
                <td>36.95</td>
                <td>40.48</td>
                <td>25.83</td>
                <td>47.54</td>
                <td>33.19</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>OmniLMM-12B</td>
                <td>12B</td>
                <td>37.89</td>
                <td>38.74</td>
                <td>36.70</td>
                <td>36.86</td>
                <td>41.77</td>
                <td>28.57</td>
                <td>46.17</td>
                <td>43.01</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InternVL-Chat-V1.1</td>
                <td>19B</td>
                <td>38.16</td>
                <td>38.93</td>
                <td>38.54</td>
                <td>40.00</td>
                <td>40.07</td>
                <td>28.16</td>
                <td>39.82</td>
                <td>27.32</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLAVA-V1.5-7B</td>
                <td>7.2B</td>
                <td>38.23</td>
                <td>37.72</td>
                <td>36.45</td>
                <td>36.65</td>
                <td>40.38</td>
                <td>25.36</td>
                <td>14.10</td>
                <td>57.09</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>Monkey-Chat</td>
                <td>9.8B</td>
                <td>38.39</td>
                <td>39.00</td>
                <td>37.16</td>
                <td>37.75</td>
                <td>42.13</td>
                <td>25.36</td>
                <td>43.91</td>
                <td>28.86</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLAVA-V1.5-7B-xtuner</td>
                <td>7.2B</td>
                <td>38.68</td>
                <td>37.96</td>
                <td>36.75</td>
                <td>36.34</td>
                <td>40.55</td>
                <td>27.52</td>
                <td>46.78</td>
                <td>43.06</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>XComposer2</td>
                <td>7B</td>
                <td>38.68</td>
                <td>38.95</td>
                <td>37.86</td>
                <td>38.52</td>
                <td>41.00</td>
                <td>28.34</td>
                <td>46.43</td>
                <td>51.87</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLAVA-InternLM-7b</td>
                <td>7.6B</td>
                <td>38.71</td>
                <td>38.84</td>
                <td>37.57</td>
                <td>36.65</td>
                <td>41.84</td>
                <td>27.46</td>
                <td>50.02</td>
                <td>40.21</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>TransCore-M</td>
                <td>13.4B</td>
                <td>38.86</td>
                <td>38.43</td>
                <td>36.09</td>
                <td>36.06</td>
                <td>42.04</td>
                <td>26.53</td>
                <td>45.34</td>
                <td>40.93</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InternVL-Chat-V1.5</td>
                <td>25.5B</td>
                <td>38.86</td>
                <td>39.32</td>
                <td>38.61</td>
                <td>40.48</td>
                <td>40.45</td>
                <td>29.27</td>
                <td>31.51</td>
                <td>24.72</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InternVL-Chat-V1.2-Plus</td>
                <td>40B</td>
                <td>39.41</td>
                <td>40.25</td>
                <td>40.68</td>
                <td>41.50</td>
                <td>40.82</td>
                <td>30.38</td>
                <td>36.50</td>
                <td>37.09</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>InternVL-Chat-V1.2</td>
                <td>40B</td>
                <td>39.52</td>
                <td>39.57</td>
                <td>39.04</td>
                <td>39.75</td>
                <td>41.05</td>
                <td>29.62</td>
                <td>41.08</td>
                <td>46.06</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>LLAVA-InternLM2-7b</td>
                <td>8.1B</td>
                <td>40.07</td>
                <td>40.15</td>
                <td>39.30</td>
                <td>39.14</td>
                <td>42.60</td>
                <td>27.76</td>
                <td><strong>50.64</strong></td>
                <td>48.25</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>DeepSeek-VL-1.3B</td>
                <td>1.3B</td>
                <td>40.25</td>
                <td>40.54</td>
                <td>40.61</td>
                <td>40.71</td>
                <td>42.13</td>
                <td>27.64</td>
                <td>48.71</td>
                <td>21.38</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>MiniCPM-V</td>
                <td>2.8B</td>
                <td>40.95</td>
                <td>40.89</td>
                <td>39.48</td>
                <td>39.18</td>
                <td>44.08</td>
                <td>27.00</td>
                <td>42.87</td>
                <td>32.09</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>DeepSeek-VL-7B</td>
                <td>7.3B</td>
                <td>41.73</td>
                <td>42.90</td>
                <td>43.87</td>
                <td>43.60</td>
                <td>44.32</td>
                <td>26.59</td>
                <td>44.16</td>
                <td>18.74</td>
              </tr>
              <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td>MiniCPM-V2</td>
                <td>2.8B</td>
                <td>41.79</td>
                <td>42.13</td>
                <td>41.11</td>
                <td>41.41</td>
                <td>45.03</td>
                <td>25.95</td>
                <td>50.12</td>
                <td>32.62</td>
              </tr>
              <tr>
                <td colspan="10" style="text-align: center; background-color: #FFF0F0;">Proprietary LVLMs</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>Claude3-Opus</td>
                <td>-</td>
                <td>32.37</td>
                <td>32.24</td>
                <td>33.56</td>
                <td>33.36</td>
                <td>32.17</td>
                <td>24.72</td>
                <td>45.31</td>
                <td>38.98</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>Qwen-VL-Max</td>
                <td>-</td>
                <td>41.34</td>
                <td>41.70</td>
                <td>44.23</td>
                <td>44.42</td>
                <td>41.09</td>
                <td>29.10</td>
                <td>31.12</td>
                <td>25.88</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>GPT-4V</td>
                <td>-</td>
                <td>42.50</td>
                <td>43.61</td>
                <td>47.87</td>
                <td>46.58</td>
                <td>42.24</td>
                <td>30.32</td>
                <td>45.21</td>
                <td>40.59</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>Gemini 1.0</td>
                <td>-</td>
                <td>44.38</td>
                <td>44.65</td>
                <td>44.92</td>
                <td>44.96</td>
                <td><u>46.67</u></td>
                <td>27.46</td>
                <td>49.01</td>
                <td>55.09</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>Gemini 1.5</td>
                <td>-</td>
                <td><u>47.42</u></td>
                <td><u>48.03</u></td>
                <td><u>54.75</u></td>
                <td><strong>56.59</strong></td>
                <td>43.25</td>
                <td><u>34.17</u></td>
                <td>39.22</td>
                <td>39.34</td>
              </tr>
              <tr style="background-color: rgba(249, 242, 248, 1);">
                <td>GPT-4o</td>
                <td>-</td>
                <td><strong>53.53</strong></td>
                <td><strong>53.88</strong></td>
                <td><strong>57.09</strong></td>
                <td><u>56.49</u></td>
                <td><strong>53.70</strong></td>
                <td><strong>36.21</strong></td>
                <td><u>50.60</u></td>
                <td>50.90</td>
              </tr>
            </tbody>
          </table>
      </div>
      </div>
    </div>

<!-------------------------------------------------------------------- Error Analysis SECTION -------------------------------------------------------------------->
<div class="columns is-centered m-6">
  <div class="column is-full has-text-centered content">
    <h2 class="title is-3">Analysis</h2>
    <div class="content has-text-justified">
      <p>
        In our analysis of cases, we categorize the process from input to output into five major classes: Question Misunderstanding, Perceptual Error, Knowledge Deficiency, Irrelevant Responses, and Refusal to Answer. We posit that a model, upon receiving visual and textual information, undergoes two distinct stages: perception and inference. Initially, the text and visual data are input into the model. If the model comprehends the semantic content of the text, it proceeds to scrutinize the image based on the textual information. Failure to grasp the textâ€™s meaning constitutes a Question Misunderstanding. Subsequently, the model perceives the content and details of the image. An inability to accurately perceive the imageâ€™s content is classified as a Perceptual Error. Within the domain of Perceptual Error, if the model overlooks critical details, this error is termed Perceptual Error - Detail Missing (PE - Detail Missing). Conversely, if the model fails to recognize key information despite not overlooking details, it is categorized as Perceptual Error - Misinterpretation (PE - Misinterpretation).
      </p>
      <p>
        If the model correctly perceives the image, it advances to the inference stage. Errors occurring during inference are classified as Knowledge Deficiency. If the model derives an incorrect or outdated response based on accurate perception, this constitutes Lack of Knowledge. If the model erroneously deems the information provided by the image insufficient to formulate a correct response, despite adequate information being available, this error is termed Unable to Determine. Additionally, if the model produces responses devoid of logical coherence, rendering the response logic unanalyzable, such errors fall under Irrelevant Responses. Another scenario arises when the model refrains from answering due to adherence to information security protocols, precluding analysis of its response logic. This error is designated as Refusal to Answer.
      </p>
    </div>
    <div class="content has-text-centered">
      <img src="static/images/ErrorClassification.png" alt="error distribution" width="75%">
      <p>
        The flowchart of error classification process for evaluating model performance from input to output, encompassing stages from question understanding to knowledge analysis
      </p>
    </div>
  </div>
</div>

<!-------------------------------------------------------------------- Error Example  -------------------------------------------------------------------->

<div class="columns is-centered m-6">
  <div class="column is-full has-text-centered content">
    <h2 class="title is-3" id="examples">Error Examples</h2>
    <div id="results-carousel" class="carousel results-carousel">
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/irrelevant_response_AR_ID_image_atypical_appearance_of_COVID-19.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/irrelevant_response_AR_OS_image_fractures_on_the_left_part_of_lowerlimb.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/irrelevant_response_ASR_OG_image_ovary.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/lack_of_knowledge_DD_PM_mask_pneumothorax.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/lack_of_knowledge_NT_O_mask_choroidal_layer.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/Lok1_SG_LMP_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/Lok2_CR_LMP_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-D-1_C_H_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-D-2_SWR_GS_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-D-3_OR-T_PM_mask.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-M-1_AR_LMP_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-M-2_NT_N_mask.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-M-3_DD_CS_bbox.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/PE-M-4_DD_D_mask.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/question_misunderstanding_BVR_O_mask_retinal_vessel.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/question_misunderstanding_SWR_GH_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/unable_to_determine_AR_OG_image_endocervical.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/incorrect/Unable1_DD_OM_image.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
    </div>
  </div>
</div>
<!-------------------------------------------------------------------- Correct Example -------------------------------------------------------------------->

<div class="columns is-centered m-6">
  <div class="column is-full has-text-centered content">
    <h2 class="title is-3">Correct Examples</h2>
    <div id="results-carousel" class="carousel results-carousel">
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/advanced glaucoma.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/basophil.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_BVR_H_mask_renal_artery.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_CR_H_bbox_white_blood_cell.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_DD_CS_mask_cardiomegaly.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_DD_PM_contour_rib_fracture.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_NT_O_mask_choroidal_layer.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_OR-T_PM_mask_lung.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_SAR_U_bbox_correct.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/correct_SIR_GS_mask_instrument_suction.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/counting.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/DD_PM_bbox_correctg_atelectasis.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/OR-HN_E_mask_correct_thyroid_gland.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/OR-P_U_contour_correct_prostate.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/SIR_GS_bbox_correct.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/surgicalworkflow.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/ulcerative_colitis.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
      <div class="box m-5">
        <div class="content has-text-centered">
          <img src="static/images/QA/correct/urology_kidney.png" alt="grade-lv" width="60%"/>
        </div>
      </div>
    </div>
  </div>
</div>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
function changeButtonText() {
  var button = document.getElementById('toggleButton');
  var table1 = document.getElementById('table1');
  var table2 = document.getElementById('table2');
  var table3 = document.getElementById('table3');

  if (button.innerHTML.includes("Clinical VQA Tasks Results")) {
    button.innerHTML = "<b style='font-size: larger;'>Departments Results</b> (Click to Switch)";
    table1.classList.add('hidden');
    table2.classList.remove('hidden');
    table3.classList.add('hidden');
  } else if (button.innerHTML.includes("Departments Results")) {
    button.innerHTML = "<b style='font-size: larger;'>Perceptual Granularities Results</b> (Click to Switch)";
    table1.classList.add('hidden');
    table2.classList.add('hidden');
    table3.classList.remove('hidden');
  } else {
    button.innerHTML = "<b style='font-size: larger;'>Clinical VQA Tasks Results</b> (Click to Switch)";
    table1.classList.remove('hidden');
    table2.classList.add('hidden');
    table3.classList.add('hidden');
  }
}
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');

    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

  // function toggleTables () {
  //     var table1 = document.getElementById('table1');
  //     var table2 = document.getElementById('table2');
  //     var table3 = document.getElementById('table3');
  //     table1.classList.toggle('hidden');
  //     table2.classList.toggle('hidden');
  //     table3.classList.toggle('hidden');
      
  //     var desc1 = document.querySelector('p.validation-desc');
  //     var desc2 = document.querySelector('p.test-desc');
  //     desc1.classList.toggle('hidden');
  //     desc2.classList.toggle('hidden');
  // }

  // document.getElementById('toggleButton').addEventListener('click', toggleTables);

  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Adept Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B-Chat',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Yi-VL-34B',
        data: [51.0, 39.9, 34.0, 41.6],
        backgroundColor: 'rgba(42, 149, 235, 0.6)',
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'LLaVA-1.6-34B',
        data: [56.1, 43.4, 34.4, 44.7],
        backgroundColor: 'rgba(183, 156, 220, 0.6)',
        borderColor: 'rgba(183, 156, 220, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(183, 156, 220, 1)'
      },
      {
        label: 'InternVL-Chat-V1.2',
        data: [56.2, 44.8, 37.8, 46.2],
        backgroundColor: 'rgba(143, 169, 209, 0.6)',
        borderColor: 'rgba(143, 169, 209, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(143, 169, 209, 1)'
      },
      {
        label: 'VILA1.5',
        data: [58.1, 45.5, 36.8, 46.9],
        backgroundColor: 'rgba(172, 199, 176, 0.6)',
        borderColor: 'rgba(172, 199, 176, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(172, 199, 176, 1)'
      },
      {
        label: 'GPT-4V(ision) (Playground)',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });

  const canvas_image = document.getElementById('single_vs_multiple_chart');
  canvas_image.style.width = '500px';
  canvas_image.style.height = '120px';
  const svm = document.getElementById('single_vs_multiple_chart').getContext('2d');
  const single_vs_multiple_chart = new Chart(svm, {
    type: 'bar',
    data: {
      labels: ['InternLM-XComposer2-VL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V(ision) (Playground)'],
      datasets: [{
        label: 'Single Image',
        data: [38.6, 42, 45.1, 46.9, 47, 56.1],
        backgroundColor: 'rgba(42, 149, 235, 0.6)', 
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'Multiple Image',
        data: [34.5, 36.6, 40, 38.4, 45.9, 51.7],
        backgroundColor: 'rgba(255, 153, 78, 0.6)', 
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Overall',
        data: [38.2, 41.6, 44.7, 46.2, 46.9, 55.7],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',  
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 80,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });


  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 38.5, 40.8, 44.6, 42.8, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 33.6, 40.2, 37.8, 39.9, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 43.6, 44.9, 44.3, 47.6, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 51.9, 57.3, 58.4, 60.9, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 30.4, 32.5, 35.6, 38.7, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 67.3, 68.9, 73.1, 71.7, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 31, 33.9, 35.7, 37.8, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 37.3, 33.1, 39.4, 37.6, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 47.8, 50.7, 52.6, 51.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 50.2, 57.3, 56.1, 52.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 49.1, 54.9, 50.4, 56.6, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 44.9, 51.5, 48, 48.5, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 45.7, 45.7, 48.9, 52.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 52.4, 58.2, 58.2, 62.4, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 30.9, 37.7, 40.1, 36.4, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 43.2, 33.6, 37, 41.1, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 30.8, 33.8, 36.8, 34.6, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 64.9, 63.4, 71, 74.8, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 65.8, 69.2, 76.9, 71.8, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 62.6, 62.6, 67, 70.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 52.9, 60, 51.4, 57.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Other " chart
    const data_Other   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 60, 61.7, 60, 68.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 66.7, 68.4, 71.9, 75.4, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 73.8, 73.8, 76.2, 81, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 50, 66.7, 63.3, 63.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 42.9, 42.9, 57.1, 42.9, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 45, 30, 30, 30, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 50, 68.8, 62.5, 68.8, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 57.1, 78.6, 78.6, 71.4, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 80, 70, 80, 80, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>
<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' â†‘';
  }
  .desc::after {
      content: ' â†“';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* é¼ æ ‡æ‚¬åœæ—¶çš„é˜´å½±æ•ˆæžœ */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>

    <!-- End of Statcounter Code -->

  </body>
  </html>
